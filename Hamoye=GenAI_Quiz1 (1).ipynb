{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Understanding Prompt Engineering"
      ],
      "metadata": {
        "id": "Jb_WKsW15NQe"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "61VPMWWVmaH0"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "# update or install the necessary libraries\n",
        "!pip install openai==v0.28.1\n",
        "!pip install --upgrade python-dotenv\n",
        "!pip install --upgrade langchain"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "import os\n",
        "import IPython\n",
        "from dotenv import load_dotenv\n"
      ],
      "metadata": {
        "id": "OIKOcc_2ma0J"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "load_dotenv()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6e8wEQrjppsr",
        "outputId": "50523eb8-2e6f-48f5-ab0a-113fdafc43c8"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# openai.api_key = os.getenv(\"openAI_Key\")\n"
      ],
      "metadata": {
        "id": "Eg3LA2n6poNb"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def AI_params(\n",
        "    model=\"gpt-3.5-turbo-instruct\",\n",
        "    temperature=0.7,\n",
        "    max_tokens=256,\n",
        "    top_p=1,\n",
        "    frequency_penalty=0,\n",
        "    presence_penalty=0,\n",
        "):\n",
        "    \"\"\"set openai parameter\"\"\"\n",
        "    openai_params = {}\n",
        "\n",
        "    openai_params['model'] = model\n",
        "    openai_params['temperature'] = temperature\n",
        "    openai_params['max_tokens'] = max_tokens\n",
        "    openai_params['top_p'] = top_p\n",
        "    openai_params['frequency_penalty'] = frequency_penalty\n",
        "    openai_params['presence_penalty'] = presence_penalty\n",
        "    return openai_params\n",
        "\n",
        "def query_completeness(params, prompt):\n",
        "    \"\"\"Get completion from openai api\"\"\"\n",
        "    response = openai.Completion.create(\n",
        "        engine = params['model'],\n",
        "        prompt = prompt,\n",
        "        temperature = params['temperature'],\n",
        "        max_tokens = params['max_tokens'],\n",
        "        top_p = params['top_p'],\n",
        "        frequency_penalty = params['frequency_penalty'],\n",
        "        presence_penalty = params['presence_penalty'],\n",
        "    )\n",
        "    return response"
      ],
      "metadata": {
        "id": "7xSibjDlmbWT"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "params = AI_params()\n",
        "\n",
        "prompt = \"Roses are\"\n",
        "\n",
        "response = query_completeness(params, prompt)"
      ],
      "metadata": {
        "id": "_ffHWwEzmbdb"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DEoAnEQRzq45",
        "outputId": "b93eea74-3d30-40cb-ea7f-5c7038379419"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<OpenAIObject text_completion id=cmpl-9KS9ZmNMvqbWP5mqjHzfL5IqjR5ac at 0x7926d981f240> JSON: {\n",
              "  \"id\": \"cmpl-9KS9ZmNMvqbWP5mqjHzfL5IqjR5ac\",\n",
              "  \"object\": \"text_completion\",\n",
              "  \"created\": 1714661809,\n",
              "  \"model\": \"gpt-3.5-turbo-instruct\",\n",
              "  \"choices\": [\n",
              "    {\n",
              "      \"text\": \" pink\\n\\nViolets are blue\\n\\nYou make me happy\\n\\nIn everything you do\\n\\nYour smile is so bright\\n\\nAnd your laughter so sweet\\n\\nBeing around you\\n\\nIs truly a treat\\n\\nYou're kind and caring\\n\\nAnd always there\\n\\nI'm grateful to have you\\n\\nAs a friend so rare\\n\\nThank you for being you\\n\\nAnd brightening up my days\\n\\nI'm lucky to know you\\n\\nIn so many ways\\n\\nSo here's a little poem\\n\\nTo let you know\\n\\nYou're loved and appreciated\\n\\nMore than you'll ever know.\",\n",
              "      \"index\": 0,\n",
              "      \"logprobs\": null,\n",
              "      \"finish_reason\": \"stop\"\n",
              "    }\n",
              "  ],\n",
              "  \"usage\": {\n",
              "    \"prompt_tokens\": 3,\n",
              "    \"completion_tokens\": 112,\n",
              "    \"total_tokens\": 115\n",
              "  }\n",
              "}"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "IPython.display.Markdown(response.choices[0].text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 490
        },
        "id": "YGxrWLD4qEKC",
        "outputId": "e7964a8c-8ccb-40a7-b10b-c76cad8c1367"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": " pink\n\nViolets are blue\n\nYou make me happy\n\nIn everything you do\n\nYour smile is so bright\n\nAnd your laughter so sweet\n\nBeing around you\n\nIs truly a treat\n\nYou're kind and caring\n\nAnd always there\n\nI'm grateful to have you\n\nAs a friend so rare\n\nThank you for being you\n\nAnd brightening up my days\n\nI'm lucky to know you\n\nIn so many ways\n\nSo here's a little poem\n\nTo let you know\n\nYou're loved and appreciated\n\nMore than you'll ever know."
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Hamoye-OpenAI Questions"
      ],
      "metadata": {
        "id": "dgBE9gja8ESu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response=openai.ChatCompletion.create(\n",
        "    model=\"gpt-3.5-turbo\",\n",
        "    messages=[\n",
        "        {\"role\":\"system\", \"content\":\"Translate the following sentence into Spanish concisely\"},\n",
        "        {'role':'user',\"content\" :'what time is the meeting'}\n",
        "    ],\n",
        "    temperature=0,\n",
        "    max_tokens=100,\n",
        "    top_p=1,\n",
        ")\n",
        "\n",
        "IPython.display.Markdown(response.choices[0].message['content'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 46
        },
        "id": "rBn4OFpLmbgU",
        "outputId": "3c74a274-d13f-4bd3-fca5-e383021fb220"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "¿A qué hora es la reunión?"
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response2 = openai.ChatCompletion.create(\n",
        "    model ='gpt-3.5-turbo',\n",
        "    messages = [\n",
        "        {'role':'system','content':'Explain the technical concept briefly enough to fit as an MCQ option.'},\n",
        "        {'role':'user',\"content\" :'What is cloud computing?'}\n",
        "    ],\n",
        "    temperature =0,\n",
        "    max_tokens =30,\n",
        "    top_p =1\n",
        ")\n",
        "IPython.display.Markdown(response2.choices[0].message['content'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 64
        },
        "id": "DWjCbJ5hmbj0",
        "outputId": "728465a7-82d4-4c61-ebd5-018d1040dfbb"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Cloud computing is a technology that allows users to access and store data, applications, and services over the internet instead of on a local computer or server."
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response3 = openai.ChatCompletion.create(\n",
        "    model ='gpt-3.5-turbo',\n",
        "    messages = [\n",
        "        {'role':'system','content':'Classify the following text’s tone in a brief form that could fit as an MCQ option'},\n",
        "        {'role':'user',\"content\" :'The meeting was cancelled due to unforeseen circumstances.'}\n",
        "    ],\n",
        "    temperature =0,\n",
        "    max_tokens =30,\n",
        "    top_p =1\n",
        ")\n",
        "IPython.display.Markdown(response3.choices[0].message['content'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 46
        },
        "id": "iCdFQYLC4sHV",
        "outputId": "2b765631-ab35-444c-e579-6aeece469556"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Neutral"
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response4 = openai.ChatCompletion.create(\n",
        "    model ='gpt-3.5-turbo',\n",
        "    messages = [\n",
        "        {'role':'system','content':'you are a knowledgeable assistant. A user will ask a question and you should provide a clear and concise answer briefly enough to fit as an MCQ option'},\n",
        "        {'role':'user',\"content\" :'what causes the Northern Lights?'}\n",
        "    ],\n",
        "    temperature =0,\n",
        "    max_tokens =150,\n",
        "    top_p =1\n",
        ")\n",
        "IPython.display.Markdown(response4.choices[0].message['content'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 46
        },
        "id": "KHKgnSwF5WMg",
        "outputId": "d211e2fd-54b9-4630-ec07-9da5c730504a"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Solar wind interacting with the Earth's magnetic field causes the Northern Lights."
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response5 = openai.ChatCompletion.create(\n",
        "    model ='gpt-3.5-turbo',\n",
        "    messages = [\n",
        "        {'role':'system','content':'Provide a concise fact about the event in history mentioned by the user briefly enough to fit as an MCQ option.'},\n",
        "        {'role':'user',\"content\" :'What was the main cause of the Americam civil war?'}\n",
        "    ],\n",
        "    temperature =0,\n",
        "    max_tokens =40,\n",
        "    top_p =1\n",
        ")\n",
        "IPython.display.Markdown(response5.choices[0].message['content'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 46
        },
        "id": "onuhkIXl5kI-",
        "outputId": "8b125346-d82f-4ff9-c18d-191a90a982dc"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "The main cause of the American Civil War was the issue of slavery."
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response6 = openai.ChatCompletion.create(\n",
        "    model ='gpt-3.5-turbo',\n",
        "    messages = [\n",
        "        {'role':'system','content':'Provide a brief, accurate answer to the user’s question that can be used as an MCQ option.'},\n",
        "        {'role':'user',\"content\" :'Who is known as the father of computer science?'}\n",
        "    ],\n",
        "    temperature =0,\n",
        "    max_tokens =30,\n",
        "    top_p =1\n",
        ")\n",
        "IPython.display.Markdown(response6.choices[0].message['content'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 46
        },
        "id": "yO2-4ru06P48",
        "outputId": "6cfa503d-73e7-483c-d736-b6ffd3d770a6"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Alan Turing."
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response7 = openai.ChatCompletion.create(\n",
        "    model ='gpt-3.5-turbo',\n",
        "    messages = [\n",
        "        {'role':'system','content':\"you are to summarize the rpovided text into a concise form, maintaining the key points and context, briefly enough toi fit as an MCQ option\"},\n",
        "        {'role':'user',\"content\" :\"the economy has been growing steadily over the past few quarters, driven by increases in consumer spending and substantial investments in renewable energy infrastructur. unemployment rates have also fallen to record lows as new industries are creating more jobs\"}\n",
        "    ],\n",
        "    temperature =0,\n",
        "    max_tokens =100,\n",
        "    top_p =1\n",
        ")\n",
        "IPython.display.Markdown(response7.choices[0].message['content'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 64
        },
        "id": "9302ilMf6eRF",
        "outputId": "1ee230b2-6766-4cac-8469-b5b07d3b565d"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "The economy has been growing steadily due to increased consumer spending and investments in renewable energy infrastructure, leading to record low unemployment rates with new industries creating more jobs."
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response8 =  openai.ChatCompletion.create(\n",
        "    model ='gpt-3.5-turbo',\n",
        "    messages = [\n",
        "        {'role':'system','content':\"you are to classify the provided text\"},\n",
        "        {'role':'user',\"content\" :\"I had an awful experience at the restaurant. The food was bland and the service was slow.\"}\n",
        "    ],\n",
        "    temperature =0,\n",
        "    max_tokens =16,\n",
        "    top_p =1\n",
        ")\n",
        "IPython.display.Markdown(response8.choices[0].message['content'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 46
        },
        "id": "fF4Q32GB6rYn",
        "outputId": "cb135ffd-9cad-4026-b0dd-f6519af485cd"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Sentiment: Negative"
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response9 = openai.ChatCompletion.create(\n",
        "    model ='gpt-3.5-turbo',\n",
        "    messages = [\n",
        "        {'role':'system','content':\"summarize the following text into a concise phrase suitable for an MCQ answer option\"},\n",
        "        {'role':'user',\"content\" :\"The internet was developed to help researchers communicate and share computing resources. Today, it connects millions of people and devices across the globe.\"}\n",
        "    ],\n",
        "    temperature =0,\n",
        "    max_tokens =30,\n",
        "    top_p =1\n",
        ")\n",
        "IPython.display.Markdown(response9.choices[0].message['content'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 46
        },
        "id": "i-FGkNdw7e2X",
        "outputId": "74a11c3c-6a0d-412d-b2cb-cefc9838c210"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "The internet was developed for research communication and resource sharing, now connecting millions globally."
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response10 = openai.ChatCompletion.create(\n",
        "    model ='gpt-3.5-turbo',\n",
        "    messages = [\n",
        "        {'role':'system','content':\"you will be provided with a sentence in english and your task is to translate it into german\"},\n",
        "        {'role':'user',\"content\" :\"How do you say 'I love to travel' in German?\"}\n",
        "    ],\n",
        "    temperature =0,\n",
        "    max_tokens =64,\n",
        "    top_p =1\n",
        ")\n",
        "IPython.display.Markdown(response10.choices[0].message['content'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 46
        },
        "id": "OxUYLZSc7sUa",
        "outputId": "455a40ab-f17a-4dae-860d-fd7e87fcae07"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "\"Ich liebe es zu reisen.\""
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WOsz8JgG7sXY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jYnsMtju7saD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4VR3Hyrp7scE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2UuzRzID7sfw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XPL21xoU7sv7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}